{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates the URLs for ma-appellatecourts.org which we will want to download. There is probably no need to run this again unless we need to capture more current cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_url(base, case_type, year, number):\n",
    "    \"\"\"\n",
    "    Given a case type, year, and number, generate the URL for it on the MA Appellate Court website\n",
    "    \n",
    "    Input:\n",
    "        base: base of URL\n",
    "        case type: Type of case in J, P, SJ, and SJC\n",
    "        year: Year of case\n",
    "        number: Case number\n",
    "    Output:\n",
    "        URL to case\n",
    "    \"\"\"\n",
    "    \n",
    "    if case_type in [\"J\", \"P\"]: # format: http://www.ma-appellatecourts.org/display_docket.php?src=party&dno=1999-P-1\n",
    "        return base + str(year) + \"-\" + case_type + \"-\" + str(number)\n",
    "    elif case_type in [\"SJ\"]: # format: http://www.ma-appellatecourts.org/display_docket.php?src=party&dno=SJ-2011-0500\n",
    "        return base + case_type + \"-\" + str(year) + \"-\" + str(number)\n",
    "    else: #http://www.ma-appellatecourts.org/display_docket.php?src=party&dno=SJC-10108\n",
    "        return base + case_type + \"-\" + str(number)\n",
    "\n",
    "base = \"http://www.ma-appellatecourts.org/display_docket.php?src=party&dno=\"\n",
    "\n",
    "# Number of J cases by year\n",
    "j_limits = {}\n",
    "j_limits[2008] = 547\n",
    "j_limits[2009] = 565\n",
    "j_limits[2010] = 589\n",
    "j_limits[2011] = 550\n",
    "j_limits[2012] = 482\n",
    "j_limits[2013] = 568\n",
    "j_limits[2014] = 514\n",
    "j_limits[2015] = 527\n",
    "j_limits[2016] = 539\n",
    "j_limits[2017] = 581\n",
    "j_limits[2018] = 130\n",
    "\n",
    "# Number of P cases by year\n",
    "p_limits = {}\n",
    "p_limits[2008] = 2156\n",
    "p_limits[2009] = 2354\n",
    "p_limits[2010] = 2281\n",
    "p_limits[2011] = 2182\n",
    "p_limits[2012] = 2023\n",
    "p_limits[2013] = 2031\n",
    "p_limits[2014] = 1995\n",
    "p_limits[2015] = 1755\n",
    "p_limits[2016] = 1758\n",
    "p_limits[2017] = 1634\n",
    "p_limits[2018] = 365\n",
    "\n",
    "# Number of SJ cases by year\n",
    "sj_limits = {}\n",
    "sj_limits[2008] = 575\n",
    "sj_limits[2009] = 668\n",
    "sj_limits[2010] = 586\n",
    "sj_limits[2011] = 555\n",
    "sj_limits[2012] = 521\n",
    "sj_limits[2013] = 503\n",
    "sj_limits[2014] = 529\n",
    "sj_limits[2015] = 561\n",
    "sj_limits[2016] = 536\n",
    "sj_limits[2017] = 511\n",
    "sj_limits[2018] = 125\n",
    "\n",
    "# Lower and upper limit of SJC case numbers within current window (2008-2018)\n",
    "sjc_lower = 10108\n",
    "sjc_upper = 12510\n",
    "\n",
    "# Links to all cases\n",
    "links = []\n",
    "\n",
    "# Generate all the links based on the above controls\n",
    "for year, n in j_limits.items():\n",
    "    for i in range(n):\n",
    "        links.append(generate_url(base, \"J\", year, i + 1))\n",
    "for year, n in p_limits.items():\n",
    "    for i in range(n):\n",
    "        links.append(generate_url(base, \"P\", year, i + 1))\n",
    "for year, n in sj_limits.items():\n",
    "    for i in range(n):\n",
    "        links.append(generate_url(base, \"SJ\", year, i + 1))\n",
    "for i in range(sjc_upper - sjc_lower):\n",
    "    links.append(generate_url(base, \"SJC\", 0, i + sjc_lower + 1))\n",
    "\n",
    "with open(\"urls_todo.txt\", \"w\") as text_file:\n",
    "    for link in links:\n",
    "        print(link, file=text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes the URLs (from a different file than the one written to above- this way, we can limit the scope if we so desire) and pulls the text down for us to keep. Be advised that the operation succeeds even if the page we pull down is \"you've been blocked\", so be sure to remove any files that are downloaded and are too small to be court cases (in my case, the minimum size is 7 KB, which is a \"this number wasn't found\"; most cases are much larger. However, the 'blocked' responses are 3 KB, but your ISP may vary. Still these are probably always smaller than actual court cases). The main loop which controls the page reads also checks if we have the case before we pull it, so there's no need to worry about pulling duplicates (but if we pull a 'blocked' response, we do need to add it back)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "# List of user agents to choose from\n",
    "useragents = '''Mozilla/5.0 (Windows; U; ; en-NZ) AppleWebKit/527  (KHTML, like Gecko, Safari/419.3) Arora/0.8.0\n",
    "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Avant Browser; Avant Browser; .NET CLR 1.0.3705; .NET CLR 1.1.4322; Media Center PC 4.0; .NET CLR 2.0.50727; .NET CLR 3.0.04506.30)\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.8 (KHTML, like Gecko) Beamrise/17.2.0.9 Chrome/17.0.939.0 Safari/535.8\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/28.0.1469.0 Safari/537.36\n",
    "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/28.0.1469.0 Safari/537.36\n",
    "Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36\n",
    "Mozilla/5.0 (Windows NT 6.0; rv:14.0) Gecko/20100101 Firefox/14.0.1\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:15.0) Gecko/20120427 Firefox/15.0a1\n",
    "Mozilla/5.0 (Windows NT 6.2; Win64; x64; rv:16.0) Gecko/16.0 Firefox/16.0\n",
    "Mozilla/5.0 (Windows NT 6.2; rv:19.0) Gecko/20121129 Firefox/19.0\n",
    "Mozilla/5.0 (Windows NT 6.1; rv:21.0) Gecko/20130401 Firefox/21.0\n",
    "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:25.0) Gecko/20100101 Firefox/25.0\n",
    "iTunes/9.0.2 (Windows; N)\n",
    "Mozilla/5.0 (compatible; Konqueror/4.5; Windows) KHTML/4.5.4 (like Gecko)\n",
    "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; Maxthon 2.0)\n",
    "Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/533.1 (KHTML, like Gecko) Maxthon/3.0.8.2 Safari/533.1\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML like Gecko) Maxthon/4.0.0.2000 Chrome/22.0.1229.79 Safari/537.1\n",
    "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)\n",
    "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)\n",
    "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)\n",
    "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; Trident/4.0)\n",
    "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Trident/4.0)\n",
    "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)\n",
    "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Trident/5.0)\n",
    "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)\n",
    "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.2; Trident/5.0)\n",
    "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.2; WOW64; Trident/5.0)\n",
    "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; Media Center PC 6.0; InfoPath.3; MS-RTC LM 8; Zune 4.7)\n",
    "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)\n",
    "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; Trident/6.0)\n",
    "Mozilla/5.0 (compatible; MSIE 10.6; Windows NT 6.1; Trident/5.0; InfoPath.2; SLCC1; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET CLR 2.0.50727) 3gpp-gba UNTRUSTED/1.0\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\n",
    "Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko\n",
    "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.3; Trident/7.0; .NET4.0E; .NET4.0C)\n",
    "Opera/9.80 (Windows NT 6.1; U; en) Presto/2.7.62 Version/11.01\n",
    "Opera/9.80 (Windows NT 6.0) Presto/2.12.388 Version/12.14\n",
    "Opera/9.80 (Windows NT 6.1; WOW64) Presto/2.12.388 Version/12.16\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.12 Safari/537.36 OPR/14.0.1116.4\n",
    "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.29 Safari/537.36 OPR/15.0.1147.24 (Edition Next)\n",
    "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.57 Safari/537.36 OPR/18.0.1284.49\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.76 Safari/537.36 OPR/19.0.1326.56\n",
    "Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/533.17.8 (KHTML, like Gecko) Version/5.0.1 Safari/533.17.8\n",
    "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5\n",
    "Mozilla/5.0 (Windows; U; Windows NT 6.2; es-US ) AppleWebKit/540.0 (KHTML like Gecko) Version/6.0 Safari/8900.00\n",
    "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-GB; rv:1.9.1.17) Gecko/20110123 (like Firefox/3.x) SeaMonkey/2.0.12\t\t\n",
    "Mozilla/5.0 (Windows NT 5.2; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 SeaMonkey/2.7.1\n",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:12.0) Gecko/20120422 Firefox/12.0 SeaMonkey/2.9'''.split('\\n')\n",
    "\n",
    "def get_page_text(url, useragent, sleep_timings = [2, 3, 5, 8], exception_timings = [5, 10, 15]):\n",
    "    \"\"\"\n",
    "    Given a URL, return the text content\n",
    "    \n",
    "    Input:\n",
    "        url: a string representing a URL\n",
    "        useragent: our totally not fake id, officer\n",
    "        sleep_timings: list of possible numbers of seconds to wait between requests\n",
    "        exception_timings: list of possible numbers of seconds to wait between exceptions before retrying\n",
    "    Output:\n",
    "        the content of said URL\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the header\n",
    "    headers = {\"Connection\": \"close\", \"user-agent\": useragent}\n",
    "    \n",
    "    # Request until we have a result\n",
    "    page = \"\"\n",
    "    while (page == \"\"):\n",
    "        try:\n",
    "            time.sleep(random.choice(sleep_timings))\n",
    "            page = requests.get(url)\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            time.sleep(random.choice(exception_timings))\n",
    "            continue\n",
    "    \n",
    "    # Keep the page text\n",
    "    return page.text\n",
    "\n",
    "def write_page_text(url, text):\n",
    "    \"\"\"\n",
    "    Write a page's text content to a file\n",
    "    \n",
    "    Input:\n",
    "        url: a string representing the source of the text\n",
    "        text: the text content\n",
    "    Output:\n",
    "        the filename under which the content was written\n",
    "    \"\"\"\n",
    "    filename = r'C:\\Users\\jcraver\\Desktop\\BENCHMARKS\\%s.html' % url.split('dno=')[-1]\n",
    "    with open(filename, \"w\") as text_file:\n",
    "        print(text, file=text_file)\n",
    "    return filename\n",
    "\n",
    "links = set([])\n",
    "folder = r'C:\\Users\\jcraver\\Desktop\\BENCHMARKS'\n",
    "\n",
    "with open(\"urls_todo.txt\", \"r\") as text_file:\n",
    "    for line in text_file:\n",
    "        links.add(line.strip())\n",
    "\n",
    "# Get files that have already been done\n",
    "done = set([])\n",
    "for file in os.listdir(folder):\n",
    "    done.add(file)\n",
    "\n",
    "# Starting from where we left off, pull down pages and write them\n",
    "# This is to limit what we do at once (if desired)\n",
    "countdown = 1000\n",
    "processed = []\n",
    "for link in links:\n",
    "    processed.append(link)\n",
    "    # Don't download a file we already have\n",
    "    if (link.split('dno=')[-1] + '.html') in done:\n",
    "        continue\n",
    "    write_page_text(link, get_page_text(link, random.choice(useragents), [3, 5, 8, 13], [10, 20, 30]))\n",
    "    countdown -= 1\n",
    "    #print(link)\n",
    "    if countdown <= 0:\n",
    "        break\n",
    "\n",
    "# Write down what we've done\n",
    "for link in processed:\n",
    "    links.remove(link)\n",
    "with open(\"urls_todo.txt\", \"w\") as text_file:\n",
    "    for link in links:\n",
    "        print(link, file=text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the web pages themselves are links to PDFs of briefs (in many cases), but we have not acquired those for this semester's project. This could give more insight into reasons why cases were reversed for a future team; one would need to scrape the HTML pages for the links to said briefs, take the time to download them all (without getting blocked), parse them for text, and endeavor to extract meaning from said text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
